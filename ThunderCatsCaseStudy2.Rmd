---
title: "Thundercats Case Study 2"
author: "TEAM THUNDERCATS DDS SMU"
date: "7/29/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(ggplot2)
library(sqldf)
library(dplyr)
library(VGAM)
library(caret)
library(nnet)
```
```{r}
test_train_split = 0.4
```
## UDFS

  - load_data: Load the data

  - generate_interaction_string: Function for generating interaction terms
  
  - build_model_string: Generates contrast equation for regression
  
  - run_linear_model: builds/test/summarizes a linear regression model using VGAM
  
  - run_neural_model: builds/test/summarizes a neuralnetwork model using nnet
```{r}
loadData <-function(){
  attrition_data = read.csv('atttrition.csv', stringsAsFactors=TRUE)
  drop_cols = c('Over18', 'EmployeeNumber', 'EmployeeCount', 'StandardHours')
  attrition_data[,drop_cols] = list(NULL)

  #potentially biasing Observation(s)?
  attrition_data = sqldf("SELECT * FROM attrition_data WHERE JobRole <> 'Research Director'")
  
  #hacky - sqlDF is fucking up my colnames
  names(attrition_data)[1] = 'Age'
  return(attrition_data)
  #attrition_data$Education = factor(attrition_data$Education)
}
#helper functions
generate_interaction_string <- function(columns){
    #f = paste(columns, ':')
    f = c()
    for(x in columns)
      for(y in columns)
      {
        if(x != y)
          if(!is.element(glue::glue('{y}:{x}'),f))
            f = append(f, glue::glue('{x}:{y}'))
      }
    return(f)
}

build_model_string <- function(target, columns, interactions=c()){
    model = c(columns, interactions)
    target_string = glue::glue("{target} ~ ")
    model_string = paste(model, collapse="+")
    f = target_string + model_string
    return(f)
}

run_linear_model <- function(data, target, columns, interactions=c()){
    model = c(columns, interactions)
    f = build_model_string(target, columns, interactions)
    
    sample = select(data, columns, target)
    
    
    #Train Test Split
    seed = 1234
    sample_size = floor(test_train_split*nrow(sample))
    set.seed(seed)
    train_set = sample(seq_len(nrow(sample)), size=sample_size)
    
    train = sample[train_set,]
    test = sample[-train_set,]
    
    
    #Build the model
    linear_model <-vglm(as.formula(f),family = "multinomial",data=train)
    
    
    #Summarize the model
    #print(summary(linear_model))
    
    #Run Predictions
    x<-select(test, -target)
    y<-select(test, target)
    
    probability<-predict(linear_model,x,type="response")
    test$pred_log_reg<-apply(probability,1,which.max)
    test$pred_log_reg[which(test$pred_log_reg=="1")]<-levels(test[,target])[1]
    test$pred_log_reg[which(test$pred_log_reg=="2")]<-levels(test[,target])[2]
    
    
    #Accuracy of the model
    mtab<-table(test$pred_log_reg,test[,target])
    confusion = confusionMatrix(mtab)
    return(list(linear_model, f, mtab, confusion))
}
run_nn_model <- function(data, target, columns, interactions=c()){
    model = c(columns, interactions)
    f = build_model_string(target, columns, interactions)
    
    sample = select(data, columns, target)
    
    
    #Train Test Split
    seed = 1234
    sample_size = floor(test_train_split*nrow(sample))
    set.seed(seed)
    train_set = sample(seq_len(nrow(sample)), size=sample_size)
    
    train = sample[train_set,]
    test = sample[-train_set,]
    
    
    #Build the model
    neural_model <-nnet(as.formula(f),data=train,size = 4,decay = 0.0001,maxit = 500)
    
    
    #Summarize the model
    #print(summary(neural_model))
    
    #Run Predictions
    x<-select(test, -target)
    y<-select(test, target)
    
    #Predict using the model
    test$pred_nnet<-predict(neural_model,x,type='class')
    #str(f)
    #Accuracy of the model
  
    mtab<-table(test$pred_nnet,test[,target])
    #print(summary(mtab))
    confusion = confusionMatrix(mtab)
    return(list(neural_model, f, mtab, confusion))
    
  
   
}
#helper function for quick viz of percentage of employees that have left
attrition_by_category <- function(category, data){

sql_statement = glue::glue('SELECT 
                                  {category}
                                  ,Attrition
                                  ,COUNT(*)*1.0  as Count
                             FROM data 
                             GROUP BY {category}
                                     , Attrition')  
  
counts = sqldf(sql_statement)
yes =sqldf("SELECT * FROM counts WHERE Attrition = 'Yes'")
no =sqldf("SELECT * FROM counts WHERE Attrition = 'No'")
attrition_rates = sqldf(glue::glue('SELECT
          y.{category},
          y.Count as Departed,
          n.Count as Employed,
          (y.Count + n.Count) as Total,
          (y.Count/(n.Count + y.Count)) as AttritionRate
       FROM yes y
       LEFT JOIN no n ON n.{category} = y.{category}'))
print(attrition_rates)
return(ggplot(counts, aes(counts[,category], counts$Count)) + geom_bar(aes(fill = Attrition), 
   width = 0.4, position = position_dodge(width=0.5), stat="identity") + xlab(category) +
   theme(legend.position="top", legend.title = 
   element_text(),axis.title.x=element_text(), 
   axis.title.y=element_text()))
}

#helper function for extracting col names
#TODO: add cols that are factors but also ints 
factor_columns <- function(dataFrame){
  return(colnames(dataFrame[,sapply(dataFrame, is.factor) & colnames(dataFrame) != "id"]))
}

non_factor_columns <- function(dataFrame){
  return(colnames(dataFrame[, !sapply(dataFrame, is.factor) & colnames(dataFrame) != "id"]))
}


plotSatisfaction <- function(category, data, label){
  sql = glue::glue('SELECT
                   {category},
                   Attrition,
                   AVG(satisfaction_index) as AverageHappiness
                   FROM data
                   GROUP BY {category}, Attrition')
  happiness = sqldf(sql)
  return(ggplot(happiness, aes(happiness[,category], happiness$AverageHappiness)) + geom_bar(aes(fill = factor(happiness[,category])), 
   width = 0.4, position = position_dodge(width=0.5), stat="identity") + coord_flip() +  
   xlab(glue::glue('{category} {label}')) + ylab('Happiness')) 
}
```

## EDA Exploratory Questions
  
   Job Satisfaction
    
   As a proxy for happiness with current employment, we will construct an index = EnvironmentSatisfaction + JobInvolvement + JobSatisfaction (tried this - didn't do much) and look for trends across the categorical variables.
   
```{r, echo=FALSE}
satisfaction_data = loadData()
stayed = sqldf("SELECT s.*,  
                            JobSatisfaction as satisfaction_index
                            FROM satisfaction_data s
                            WHERE Attrition = 'No'")
left = sqldf("SELECT s.*,  
                            JobSatisfaction as satisfaction_index
                            FROM satisfaction_data s
                            WHERE Attrition = 'Yes'")
for(x in factor_columns(stayed)){
  if(x != 'Attrition'){  print(plotSatisfaction(x, stayed, '-Stayed'))
    print(plotSatisfaction(x, left, '-Departed'))
  }
}

```

## Variable Ranks

    Run a regression on full model to scan for variables of importance
  
```{r, echo=FALSE}
experiment_data = loadData()
experiment_target = c('Attrition')
experiment_columns = c(
                          'BusinessTravel'
                        , 'Department'
                        , 'DistanceFromHome'
                        , 'EducationField'
                        , 'EnvironmentSatisfaction'
                        , 'OverTime'
                        , 'Gender'
                        , 'HourlyRate'
                        , 'DailyRate'
                        , 'JobInvolvement'
                        , 'JobLevel'
                        , 'Education'
                        , 'JobSatisfaction'
                        , 'MaritalStatus'
                        , 'MonthlyIncome'
                        , 'MonthlyRate'
                        , 'NumCompaniesWorked'
                        , 'PerformanceRating'
                        , 'PercentSalaryHike'
                        , 'JobRole'
                        , 'Age'
                        , 'RelationshipSatisfaction'
                        , 'StockOptionLevel'
                        , 'TotalWorkingYears'
                        , 'WorkLifeBalance'
                        , 'TrainingTimesLastYear'
                        , 'YearsAtCompany'
                        , 'YearsInCurrentRole'
                        , 'YearsSinceLastPromotion'
                        , 'YearsWithCurrManager')

experiment_interactions = generate_interaction_string(c('EnvironmentSatisfaction', 'OverTime', 'WorkLifeBalance'))
linear_results = run_linear_model(experiment_data, experiment_target, experiment_columns, experiment_interactions)
```

```{r}
contrast_formula = linear_results[[2]]
print(contrast_formula)
summary(linear_results[[1]])
```

  
```{r, echo=FALSE}
summary(linear_results[[3]])
```

## Confusion Matrix

```{r}
linear_results[[4]]
```
## Full model analysis

    Accuracy of 86.57% / 70.82% Balanced 
    
    Overall - the model shows a solid gain against the naive classifier  (No Information Rate 82.13% vs Acc of 86.57%)
              
              p-value indicates strong statistical likelihood
    
    Statistically Significant Features:
    
    Travel, DistanceFromHome, EnvironmentSatisfaction, OverTime, JobInvolvement, JobLevel, 
    JobSatisfaction, MaritalStatus, NumCompaniesWorked, WorkLifeBalance, YearsInCurrentRole,
    YearsSinceLastPromotion, YearsWithCurrManager

## Let's try a reduced model

```{r}
experiment_data  =loadData()
experiment_target = c('Attrition')
experiment_columns = c(
                          'BusinessTravel'
                        , 'DistanceFromHome'
                        , 'EnvironmentSatisfaction'
                        , 'OverTime'
                        , 'JobInvolvement'
                        , 'JobLevel'
                        , 'JobSatisfaction'
                        , 'MaritalStatus'
                        , 'NumCompaniesWorked'
                        , 'WorkLifeBalance'
                        , 'YearsInCurrentRole'
                        , 'YearsSinceLastPromotion'
                        , 'YearsWithCurrManager')

experiment_interactions = generate_interaction_string(c('EnvironmentSatisfaction', 'WorkLifeBalance'))# c()
final_linear = run_linear_model(experiment_data, experiment_target, experiment_columns, experiment_interactions)
final_nn = run_nn_model(experiment_data, experiment_target, experiment_columns, experiment_interactions)


```


```{r}
contrast_formula = final_linear[[2]]
print(contrast_formula)
summary(final_linear[[1]])
```

## Neural Network Results

```{r}
summary(final_nn[[1]])
```

   
    
## Confusion Matrix (reduced)

```{r}
final_linear[[4]]
```
## Reduced model analysis

    Accuracy of 85.01% / 65.14% Balanced 
    
    Overall - the model shows a lesser gain against the naive classifier  (No Information Rate 82.13% vs Acc of 85.01%)
              
              p-value indicates  statistical likelihood
              
    Reduced model gets a close fit to the full model with far fewer variables. Further analysis is warranted to search for 
    new interaction terms and other possible variable combinations/transformations. The code above can be abstracted for 
    that task as an exercise for the user :)
    
## Confusion Matrix (neural)

    Because - why not???

```{r}
final_nn[[4]]
```  
## Barf 

    Neural network is dog poop - probably needs some hyper parameter tuning. Also left as an exercise for the user :)


## Check target balances by factor

```{r}
experiment_data = loadData()
experiment_factor_columms = c(
                          'BusinessTravel'
                        , 'EnvironmentSatisfaction'
                        , 'OverTime'
                        , 'JobInvolvement'
                        , 'JobLevel'
                        , 'JobSatisfaction'
                        , 'MaritalStatus'
                        , 'WorkLifeBalance'
                        , 'StockOptionLevel')


for(f in experiment_factor_columms){
  print(attrition_by_category(f, experiment_data))
}

```

