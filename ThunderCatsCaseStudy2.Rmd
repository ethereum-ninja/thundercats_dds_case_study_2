---
title: "Thundercats Case Study 2"
author: "TEAM THUNDERCATS DDS SMU"
date: "7/29/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(ggplot2)
library(sqldf)
library(dplyr)
library(VGAM)
library(caret)
library(nnet)
```

  # loadData: Load the data

  # generate_interaction_string: Function for generating interaction terms
  
  # build_model_string: Generates contrast equation for regression
  
  # run_linear_model: builds/test/summarizes a linear regression model using VGAM
  
  # run_neural_model: builds/test/summarizes a neuralnetwork model using nnet
```{r, echo=FALSE}
loadData <-function(){
  attrition_data = read.csv('atttrition.csv', stringsAsFactors=TRUE)
  drop_cols = c('Over18', 'EmployeeNumber', 'EmployeeCount', 'StandardHours')
  attrition_data[,drop_cols] = list(NULL)

  #potentially biasing Observation(s)?
  attrition_data = sqldf("SELECT * FROM attrition_data WHERE JobRole <> 'Research Director'")
  
  #hacky - sqlDF is fucking up my colnames
  names(attrition_data)[1] = 'Age'
  return(attrition_data)
  #attrition_data$Education = factor(attrition_data$Education)
}
#helper functions
generate_interaction_string <- function(columns, depth){
    f = paste(columns, ':')
    return(f)
}

build_model_string <- function(target, columns, interactions=c()){
    
    model = c(columns, interactions)
    target_string = glue::glue("{target} ~ ")
    model_string = paste(model, collapse="+")
    f = target_string + model_string
    return(f)
}

run_linear_model <- function(data, target, columns, interactions=c()){
    model = c(columns, interactions)
    f = build_model_string(target, columns, interactions)
    
    sample = select(data, columns, target)
    
    
    #Train Test Split
    seed = 1234
    sample_size = floor(0.3*nrow(sample))
    set.seed(seed)
    train_set = sample(seq_len(nrow(sample)), size=sample_size)
    
    train = sample[train_set,]
    test = sample[-train_set,]
    
    
    #Build the model
    linear_model <-vglm(as.formula(f),family = "multinomial",data=train)
    
    
    #Summarize the model
    print(summary(linear_model))
    
    #Run Predictions
    x<-select(test, -target)
    y<-select(test, target)
    
    probability<-predict(linear_model,x,type="response")
    test$pred_log_reg<-apply(probability,1,which.max)
    test$pred_log_reg[which(test$pred_log_reg=="1")]<-levels(test[,target])[1]
    test$pred_log_reg[which(test$pred_log_reg=="2")]<-levels(test[,target])[2]
    
    
    str(f)
    #Accuracy of the model
    mtab<-table(test$pred_log_reg,test[,target])
    confusionMatrix(mtab)
}
run_nn_model <- function(data, target, columns, interactions=c()){
    model = c(columns, interactions)
    f = build_model_string(target, columns, interactions)
    
    sample = select(data, columns, target)
    
    
    #Train Test Split
    seed = 1234
    sample_size = floor(0.3*nrow(sample))
    set.seed(seed)
    train_set = sample(seq_len(nrow(sample)), size=sample_size)
    
    train = sample[train_set,]
    test = sample[-train_set,]
    
    
    #Build the model
    neural_model <-nnet(as.formula(f),data=train,size = 4,decay = 0.0001,maxit = 500)
    
    
    #Summarize the model
    print(summary(neural_model))
    
    #Run Predictions
    x<-select(test, -target)
    y<-select(test, target)
    
    #Predict using the model
    test$pred_nnet<-predict(neural_model,x,type='class')
    str(f)
    #Accuracy of the model
  
    mtab<-table(test$pred_nnet,test[,target])
    print(summary(mtab))
    confusionMatrix(mtab)
    
    
  
   
}
#helper function for quick viz of percentage of employees that have left
attrition_by_category <- function(category){

sql_statement = glue::glue('SELECT 
                                  {category}
                                  ,Attrition
                                  ,COUNT(*)*1.0  as Count
                             FROM attrition_data 
                             GROUP BY {category}
                                     , Attrition')  
  
counts = sqldf(sql_statement)

yes =sqldf("SELECT * FROM counts WHERE Attrition = 'Yes'")
no =sqldf("SELECT * FROM counts WHERE Attrition = 'No'")

yes_bar = ggplot(yes, aes(x=yes[,category], y=yes$Count, fill=yes[,category])) + geom_bar(stat = "identity") + labs(x = category, y='# Attrition', fill=category) 
no_bar = ggplot(no, aes(x=no[,category], y=no$Count, fill=no[,category])) + geom_bar(stat = "identity") + labs(x = category, y='# Attrition', fill=category) 

attrition_rates = sqldf(glue::glue('SELECT
          y.{category},
          y.Count as Departed,
          n.Count as Employed,
          (y.Count + n.Count) as Total,
          (y.Count/(n.Count + y.Count)) as AttritionRate
       FROM yes y
       LEFT JOIN no n ON n.{category} = y.{category}'))
plot(no_bar)
plot(yes_bar)
print(attrition_rates)
#return(list(attrition_rates, yes_bar, no_bar))
}

#helper function for extracting col names
#TODO: add cols that are factors but also ints 
factor_columns <- function(dataFrame){
  return(colnames(dataFrame[,sapply(dataFrame, is.factor) & colnames(dataFrame) != "id"]))
}
```
## EDA Phase 1: Plotting
  
  # By Age (abstract into histogram analysis?)
  
## Variable Ranks
  
  #Colinearity checks?
```{r}
attrition_data = loadData()
#let's partiton by attrition and look at the data a bit
left_data = sqldf("SELECT * FROM attrition_data WHERE Attrition = 'Yes'")
stayed_data = sqldf("SELECT * FROM attrition_data WHERE Attrition = 'No'")

ggplot(data=left_data, aes(left_data$Age)) + geom_histogram(binwidth = 3) 
ggplot(data=stayed_data, aes(stayed_data$Age)) + geom_histogram(binwidth = 3) 

```

```{r}

```

 # Analysis by factor


```{r}
factors = factor_columns(attrition_data)
for(f in factors){
  attrition_by_category(f)
}

```
# Analysis:
  
  - Overtime seems to be an important factor when considering attrition rate. OF the 416 employees that worked overtime, nearly 30% of them left their positions.
  
```{r}
experiment_data = loadData()
experiment_target = c('Attrition')
experiment_columns = c(
                          'BusinessTravel'
                        , 'Department'
                        , 'DistanceFromHome'
                        , 'EducationField'
                        , 'EnvironmentSatisfaction'
                        , 'OverTime'
                        , 'Gender'
                        , 'HourlyRate'
                        , 'DailyRate'
                        , 'JobInvolvement'
                        , 'JobLevel'
                        , 'Education'
                        , 'JobSatisfaction'
                        , 'MaritalStatus'
                        , 'MonthlyIncome'
                        , 'MonthlyRate'
                        , 'NumCompaniesWorked'
                        , 'PerformanceRating'
                        , 'PercentSalaryHike'
                        , 'JobRole'
                        , 'Age'
                        , 'RelationshipSatisfaction'
                        , 'StockOptionLevel'
                        , 'TotalWorkingYears'
                        , 'WorkLifeBalance'
                        , 'TrainingTimesLastYear'
                        , 'YearsAtCompany'
                        , 'YearsInCurrentRole'
                        , 'YearsSinceLastPromotion'
                        , 'YearsWithCurrManager')

experiment_interactions = c()
run_linear_model(experiment_data, experiment_target, experiment_columns, experiment_interactions)

#run_nn_model(experiment_data, experiment_target, experiment_columns, experiment_interactions)
```
## Full model analysis

    Accuracy of 84.17% vs target balance of {}
    
    
    Statistically Significant Features:
    
    Travel, DistanceFromHome, EnvironmentSatisfaction, OverTime, JobInvolvement, JobLevel, 
    JobSatisfaction, MaritalStatus, NumCompaniesWorked, WorkLifeBalance, YearsInCurrentRole,
    YearsSinceLastPromotion, YearsWithCurrManager

## Let's try a reduced model

```{r}
experiment_data  =loadData()
experiment_target = c('Attrition')
experiment_columns = c(
                          'BusinessTravel'
                        , 'DistanceFromHome'
                        , 'EnvironmentSatisfaction'
                        , 'OverTime'
                        , 'JobInvolvement'
                        , 'JobLevel'
                        , 'JobSatisfaction'
                        , 'MaritalStatus'
                        , 'NumCompaniesWorked'
                        , 'WorkLifeBalance'
                        , 'YearsInCurrentRole'
                        , 'YearsSinceLastPromotion'
                        , 'YearsWithCurrManager')

experiment_interactions =c()# c('JobLevel:YearsSinceLastPromotion:EnvironmentSatisfaction')
run_linear_model(experiment_data, experiment_target, experiment_columns, experiment_interactions)
run_nn_model(experiment_data, experiment_target, experiment_columns, experiment_interactions)


```
    


# Check train vs test sets for bias


```{r}
#str(sample)
#summary(sample)
#summary(train)
#summary(test)

```